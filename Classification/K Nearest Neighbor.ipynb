{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe\n",
      "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0\n",
      "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0\n",
      "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0\n",
      "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0\n",
      "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0\n",
      "..       ...    ...   ...   ...    ...   ...   ...   ...  ...\n",
      "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0\n",
      "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0\n",
      "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0\n",
      "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0\n",
      "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0\n",
      "\n",
      "[214 rows x 9 columns]\n",
      "     Type\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "..    ...\n",
      "209     7\n",
      "210     7\n",
      "211     7\n",
      "212     7\n",
      "213     7\n",
      "\n",
      "[214 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.tree\n",
    "data=pd.read_csv(\"D:\\Coursera\\GlassClassification.csv\")\n",
    "#print(data)\n",
    "\n",
    "#Separating Indepent data and Target data\n",
    "X=data.drop(['Type'],axis=1)\n",
    "print(X)\n",
    "y=data[['Type']]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,jaccard_score,f1_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Jaccard Score is : 0.5765432098765431\n",
      "The average F1 Score is : 0.6976744186046513\n",
      "The average accuracy is : 0.6976744186046513\n"
     ]
    }
   ],
   "source": [
    "model=KNeighborsClassifier(n_neighbors=7)\n",
    "n=10\n",
    "totalAccuracy=0\n",
    "totalJaccardScore=0\n",
    "totalF1Score=0\n",
    "totalLogLoss=0\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    #splitting the model\n",
    "    xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "    \n",
    "    #Train the model\n",
    "    model.fit(xTrain,yTrain.values.ravel())\n",
    "    \n",
    "    #Predict the outputs\n",
    "    yPredict=model.predict(xTest)\n",
    "    \n",
    "    #Generating the Evaluation score\n",
    "        \n",
    "        #Accuracy Measure\n",
    "    immAccuracy=accuracy_score(yTest,yPredict)\n",
    "    totalAccuracy=totalAccuracy+immAccuracy\n",
    "        \n",
    "        #Jaccard Score Measure\n",
    "    immJaccardScore=jaccard_score(yTest,yPredict,average='macro')\n",
    "    totalJaccardScore=totalJaccardScore+immJaccardScore\n",
    "        \n",
    "        #F1 Score Measure\n",
    "    immF1Score=f1_score(yTest,yPredict,average='micro')\n",
    "    totalF1Score=totalF1Score+immF1Score\n",
    "    \n",
    "    '''    #Logloass Measure\n",
    "    immLogLoss=log_loss(yTest,yPredict,eps=1e-15,normalize=True)\n",
    "    totalLogLoss=totalLogLoss+immLogLoss'''\n",
    "    \n",
    "    #print(immAccuracy)\n",
    "    #print(immJaccardScore)\n",
    "    #print(immF1Score)\n",
    "    #print(totalLogLoss)\n",
    "    #model.get_depth()\n",
    "    #print(model.get_n_leaves())\n",
    "\n",
    "# Taking the average of Evalation Scores\n",
    "avgAccuracy=totalAccuracy/n\n",
    "avgJaccardScore=totalJaccardScore/n\n",
    "avgF1Score=totalF1Score/n\n",
    "#avgLogLoss=totalLogLoss/n\n",
    "\n",
    "print(\"The average Jaccard Score is :\", avgJaccardScore)\n",
    "print(\"The average F1 Score is :\", avgF1Score)\n",
    "#print(\"The average Log Loss Score is :\", avgLogLoss)\n",
    "print(\"The average accuracy is :\", avgAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> 0.7209302325581392    0.6516666666666671    0.7209302325581392\n",
      "3 -> 0.6976744186046516    0.5258487654320984    0.6976744186046516\n",
      "5 -> 0.7209302325581392    0.5890652557319218    0.7209302325581392\n",
      "7 -> 0.6976744186046516    0.5765432098765435    0.6976744186046516\n",
      "9 -> 0.6046511627906979    0.3217592592592594    0.6046511627906979\n",
      "11 -> 0.5813953488372088    0.3057870370370371    0.5813953488372088\n",
      "13 -> 0.6279069767441856    0.3320987654320985    0.6279069767441856\n",
      "15 -> 0.6279069767441856    0.3405701754385965    0.6279069767441856\n",
      "17 -> 0.6511627906976748    0.3629629629629627    0.6511627906976748\n",
      "19 -> 0.6511627906976748    0.3509259259259262    0.6511627906976748\n",
      "21 -> 0.6744186046511624    0.3740740740740738    0.6744186046511624\n",
      "23 -> 0.6511627906976748    0.3698067632850238    0.6511627906976748\n",
      "25 -> 0.6744186046511624    0.3805619120264425    0.6744186046511624\n",
      "27 -> 0.6511627906976748    0.3698067632850238    0.6511627906976748\n",
      "29 -> 0.6511627906976748    0.3698067632850238    0.6511627906976748\n",
      "31 -> 0.6744186046511624    0.2901274926446552    0.6744186046511624\n",
      "33 -> 0.6511627906976748    0.2789337474120082    0.6511627906976748\n",
      "35 -> 0.6279069767441856    0.26746031746031745    0.6279069767441856\n",
      "37 -> 0.6279069767441856    0.2660714285714286    0.6279069767441856\n",
      "39 -> 0.6279069767441856    0.2660714285714286    0.6279069767441856\n",
      "41 -> 0.6279069767441856    0.2660714285714286    0.6279069767441856\n",
      "43 -> 0.6279069767441856    0.2660714285714286    0.6279069767441856\n",
      "45 -> 0.6279069767441856    0.26541353383458655    0.6279069767441856\n",
      "47 -> 0.5348837209302321    0.22519147519147528    0.5348837209302321\n",
      "49 -> 0.48837209302325524    0.20661759067556157    0.48837209302325524\n"
     ]
    }
   ],
   "source": [
    "kMax=50\n",
    "avgResult=[]\n",
    "for k in range(1,kMax,2):\n",
    "    model=KNeighborsClassifier(n_neighbors=k)\n",
    "    n=40\n",
    "    totalAccuracy=0\n",
    "    totalJaccardScore=0\n",
    "    totalF1Score=0\n",
    "    totalLogLoss=0\n",
    "\n",
    "    for i in range(n):\n",
    "    \n",
    "        #splitting the model\n",
    "        xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "    \n",
    "        #Train the model\n",
    "        model.fit(xTrain,yTrain.values.ravel())\n",
    "    \n",
    "        #Predict the outputs\n",
    "        yPredict=model.predict(xTest)\n",
    "    \n",
    "        #Generating the Evaluation score\n",
    "        \n",
    "            #Accuracy Measure\n",
    "        immAccuracy=accuracy_score(yTest,yPredict)\n",
    "        totalAccuracy=totalAccuracy+immAccuracy\n",
    "        \n",
    "            #Jaccard Score Measure\n",
    "        immJaccardScore=jaccard_score(yTest,yPredict,average='macro')\n",
    "        totalJaccardScore=totalJaccardScore+immJaccardScore\n",
    "        \n",
    "            #F1 Score Measure\n",
    "        immF1Score=f1_score(yTest,yPredict,average='micro')\n",
    "        totalF1Score=totalF1Score+immF1Score\n",
    "    \n",
    "        '''    #Logloass Measure\n",
    "        immLogLoss=log_loss(yTest,yPredict,eps=1e-15,normalize=True)\n",
    "        totalLogLoss=totalLogLoss+immLogLoss'''\n",
    "    \n",
    "        #print(immAccuracy)\n",
    "        #print(immJaccardScore)\n",
    "        #print(immF1Score)\n",
    "        #print(totalLogLoss)\n",
    "        #model.get_depth()\n",
    "        #print(model.get_n_leaves())\n",
    "\n",
    "    # Taking the average of Evalation Scores\n",
    "    avgAccuracy=totalAccuracy/n\n",
    "    avgJaccardScore=totalJaccardScore/n\n",
    "    avgF1Score=totalF1Score/n\n",
    "    #avgLogLoss=totalLogLoss/n\n",
    "    avgResult.append(avgAccuracy)\n",
    "    print(k, \"->\" ,avgAccuracy, \"  \" , avgJaccardScore, \"  \" , avgF1Score)\n",
    "#print(k, \"->\" ,avgResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
